{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3ae4d8-4713-4827-bdd6-6df57523aea1",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "bs4 → is the Python package name for BeautifulSoup 4, a popular library used for parsing HTML and XML documents.\n",
    "\n",
    "BeautifulSoup → is the main class provided by the library.\n",
    "\n",
    "By writing from bs4 import BeautifulSoup, you are importing that class so you can create a BeautifulSoup object and work with HTML/XML easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db4d3b8-e8d9-4ee9-968b-b516085d1a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de9472-8a85-4996-b85c-0ceaf7301fcc",
   "metadata": {},
   "source": [
    "1. import requests → loads the requests library, but you are not using it in this code.\n",
    "2. open(...).read() → opens your local file (scrap-example.html) and reads its content into a variable called htmlPage.\n",
    "3. htmlPage is just a string that contains all the HTML code from that file.\n",
    "4. The requests line is unnecessary unless you want to fetch an online webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "590e0848-4b17-45b1-8d29-f623f376117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "htmlPage=open(\"C:/Users/user/Desktop/scrap-example.html\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9172bd-c0c5-4931-843f-6134320eab76",
   "metadata": {},
   "source": [
    "1. BeautifulSoup(htmlPage, \"html.parser\") → takes your HTML text and parses it into a BeautifulSoup object.\n",
    "2. That object (soup) represents the entire HTML document as a structured parse tree.\n",
    "3. You can now search, navigate, and modify elements in the HTML using methods like .find(), .find_all(), .title, .p, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68109fd-45a2-4613-b0ee-cd92e8ad86b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=BeautifulSoup(htmlPage, \"html.parser\")\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f5ccb1-aff7-422f-a576-13671f977759",
   "metadata": {},
   "source": [
    "1. soup.html → Finds the \"html\" tag in your parsed HTML file and stores it in HTML.\n",
    "\n",
    "2. HTML.head → From inside the \"html\" tag, it extracts the \"head\" section and stores it in HEAD.\n",
    "\n",
    "3. print(HEAD) → Prints the entire \"head\" section of your HTML document (including \"title\", \"meta\", \"link\", \"style\", etc., depending on what’s inside your HTML file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15dce73d-13a0-474f-a97b-6d5aa3be8262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<title>Mad Monk Ji Gong</title>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "HTML = soup.html\n",
    "HEAD = HTML.head\n",
    "print(HEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99827fd7-c722-44c8-9bac-928a1bc963c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(HEAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c4d66-4b2c-49d1-b225-bc27cee0fb6e",
   "metadata": {},
   "source": [
    "1. soup.html.head gives you the entire \"head\" section of your HTML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31d7e37f-ac2a-40de-87a0-2bf8e17533bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<title>Mad Monk Ji Gong</title>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "head=soup.html.head\n",
    "print(HEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70810173-9e14-4f1c-8794-af6c536d3e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<title>Mad Monk Ji Gong</title>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "print(soup.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf65763-56c3-4f85-9cfe-a259ebc7c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Mad Monk Ji Gong</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36908ca-00a9-47fe-b977-452af1070247",
   "metadata": {},
   "source": [
    "1. There is more than one element with this tag, this approach will only return the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4607b46e-48c3-4518-94ae-e86829e2d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>This happened\n",
      "\t  during <a href=\"https://en.wikipedia.org/wiki/Song_dynasty\">Song Dynasty</a>.\n",
      "\t  The patchwork robe made for <strong>Guang Liang</strong>...</p>\n"
     ]
    }
   ],
   "source": [
    "print(soup.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0f613-0a08-49a0-ab18-5b98e23a50cf",
   "metadata": {},
   "source": [
    "1. soup.find(tag, ...) → finds the first occurrence of that HTML tag.\n",
    "\n",
    "2. class_=\"quote\" → filters by class name \"quote\".\n",
    " (We use class_ instead of class because class is a reserved keyword in Python.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47eab303-7021-417f-a681-6817cc72b9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"quote\">When I was strolling in the street,\n",
      "\t  <footnote>They lived in Linan</footnote> almost\n",
      "\t  everyone was calling me\n",
      "\t  <span class=\"nickname\">Virtuous Li</span> ...</p>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(\"p\", class_ = \"quote\"))   # First line is more specific: it only searches for a <p> with class quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05c98e4c-5395-4d8e-8b24-20e735effd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"nickname\">Virtuous Li</span>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(class_ = \"nickname\"))  # Second line is more general: it searches for any tag with class nickname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e2e46d-da19-48ef-9c22-f9845f29bf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>This happened\n",
      "\t  during <a href=\"https://en.wikipedia.org/wiki/Song_dynasty\">Song Dynasty</a>.\n",
      "\t  The patchwork robe made for <strong>Guang Liang</strong>...</p>, <p class=\"quote\">When I was strolling in the street,\n",
      "\t  <footnote>They lived in Linan</footnote> almost\n",
      "\t  everyone was calling me\n",
      "\t  <span class=\"nickname\">Virtuous Li</span> ...</p>]\n"
     ]
    }
   ],
   "source": [
    "Ps=soup.find_all(\"p\")  # if you want to extract all tags, you can use find_all method. It returns all elements that match the query in a list.\n",
    "print(Ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f90ca44e-4aa3-4c57-85f0-e1383670e8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Ps[0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fdd474-556e-43c8-b0ec-cb749923da28",
   "metadata": {},
   "source": [
    "## Extracting content\n",
    "The extracted elements, although they appear as text lines from the file, are not text but belong to BS internal classes. If we want to extract the text inside of the element as text, we can do this with the .text attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b39d6d-acf3-49bd-b813-3af18016029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I was strolling in the street,\n",
      "\t  They lived in Linan almost\n",
      "\t  everyone was calling me\n",
      "\t  Virtuous Li ...\n"
     ]
    }
   ],
   "source": [
    "print(Ps[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3361ddb-4336-4904-8eb1-17ceb5941078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Song_dynasty'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a[\"href\"]   #Html attributes (such as “class” or “href”) can be extracted using square brackets (like in case of dicts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae2dc450-4753-4da6-bd05-ddcc1bf5bcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quote']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ps[1][\"class\"]    # the class of the second paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d467d8d6-5270-44eb-9e64-ce2322c4016f",
   "metadata": {},
   "source": [
    "We can also explicitly get the tag using name attribute. By inverting the previous example, let’s find the first element of class “quote” and print it’s tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "474f7cc7-ab19-4caa-b5f6-170a04b04c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(class_='quote').name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f8d9a-89af-448b-96e2-30d4433bfe4c",
   "metadata": {},
   "source": [
    "##  Moving up and down the tree\n",
    "Beautiful Soup uses concepts children, siblings, descendants, and parents to navigate the html tree. Children are elements that are directly inside of a parent element and not inside other elements that are inside parent elements (those are grandchildren). Parents are elements that children are directly inside\n",
    "\n",
    "One can get an iterable collections of all first-level children of a tag with the children attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cad7409e-0511-4b24-a33d-d8b986a99275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "h1\n",
      "None\n",
      "p\n",
      "None\n",
      "h2\n",
      "None\n",
      "p\n",
      "None\n",
      "h2\n",
      "None\n",
      "div\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "children = soup.body.children\n",
    "for child in children:\n",
    "    print(child.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c2e62ff-36ff-4ce3-b11d-d869f5528bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<h1>Li Visits Buddha</h1>\n"
     ]
    }
   ],
   "source": [
    "children = list(soup.body.children)\n",
    "print(children[0])  # line break after body, before header\n",
    "print(children[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5677c79-75ae-434a-966f-b3121f66b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(children[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88406858-8ab1-4ba8-965c-e75e5df6a958",
   "metadata": {},
   "source": [
    "If you want to list all descendants of an element, i.e. to include grandchildren and such, you can use descendants instead of children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1664723e-60fe-4601-9876-82820caed9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "h1\n",
      "None\n",
      "None\n",
      "p\n",
      "None\n",
      "a\n",
      "None\n",
      "None\n",
      "strong\n",
      "None\n",
      "None\n",
      "None\n",
      "h2\n",
      "None\n",
      "None\n",
      "p\n",
      "None\n",
      "footnote\n",
      "None\n",
      "None\n",
      "span\n",
      "None\n",
      "None\n",
      "None\n",
      "h2\n",
      "None\n",
      "None\n",
      "div\n",
      "None\n",
      "table\n",
      "None\n",
      "thead\n",
      "None\n",
      "tr\n",
      "None\n",
      "th\n",
      "None\n",
      "None\n",
      "th\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "tbody\n",
      "None\n",
      "tr\n",
      "None\n",
      "td\n",
      "None\n",
      "None\n",
      "td\n",
      "None\n",
      "None\n",
      "None\n",
      "tr\n",
      "None\n",
      "td\n",
      "None\n",
      "None\n",
      "td\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "children = soup.body.descendants\n",
    "for child in children:\n",
    "    print(child.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d78e4-691f-481a-aa20-95af745b6bbe",
   "metadata": {},
   "source": [
    "Moving horizontally among the same level elements proceeds with find_next_sibling, find_next_siblings, find_previous_sibling and find_previous_siblings. Moving back- and forth disregarding the nesting level can be done with find_next, find_all_next, find_previous and find_all_previous. The siblings and all versions find all the occurrences, the others find just the first occurrence. All these functions accept various parameters so one can specify tag names and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5525a013-952a-4414-a244-a1c1180d2d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Li Begs for a Son'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us extract second “p” inside of “body”, and thereafter move back to first preceding “h2”\n",
    "ps = soup.body.find_all(\"p\")  # list of both b-s\n",
    "p = ps[1]  # 2nd p\n",
    "h2 = p.find_previous_sibling(\"h2\")  # h2 before the 2nd p\n",
    "h2.text  # print the text inside h2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e55346-da64-408d-869d-7192da1cea72",
   "metadata": {},
   "source": [
    "###  Removing elements from the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc52cac9-6665-4b32-b7e2-c8bf6a0ff210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I was strolling in the street,\n",
      "\t  They lived in Linan almost\n",
      "\t  everyone was calling me\n",
      "\t  Virtuous Li ...\n"
     ]
    }
   ],
   "source": [
    "p = soup.body.find(\"p\", class_ = \"quote\").text\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf28e02-ada2-4a16-bfa2-caa9fce38c4d",
   "metadata": {},
   "source": [
    "Linan in the second line belongs to the footnote and the following almost belongs to the main text, but there is no way to tell this based on the printout. Sometimes this is what we want, e.g. when we strip text from its attributes like “i” and “b” (for italic and bold respectively). But here it is clearly undesirable. As a solution, we can delete the “footnote” element using extract method. However, if we extract an element, it will be deleted from the whole source tree and we cannot access it later. So we may want to make a copy of the element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "221bb5f5-2ed6-47bc-8e53-32d4cc1962f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I was strolling in the street,\n",
      "\t   almost\n",
      "\t  everyone was calling me\n",
      "\t  Virtuous Li ...\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "p = soup.body.find(\"p\", class_ = \"quote\")  # find the quote paragraph\n",
    "p = copy.copy(p)  # make copy of p (and forget the original)\n",
    "footnote = p.footnote.extract()  # find the first footnote there and remove it\n",
    "print(p.text)  # print the final text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce019753-1bbd-4c69-b988-84f1574a85eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I was strolling in the street,\n",
      "\t  They lived in Linan almost\n",
      "\t  everyone was calling me\n",
      "\t  Virtuous Li ...\n"
     ]
    }
   ],
   "source": [
    "p = soup.body.find(\"p\", class_ = \"quote\")\n",
    "print(p.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75cce4-a1d4-4f70-9140-697da24a5f17",
   "metadata": {},
   "source": [
    "1. urllib.request is a Python module for handling URLs.\n",
    "2. urljoin is a function inside this module that can combine a base URL and a relative URL into a full absolute URL.\n",
    "3. By importing it this way, you can just call urljoin(...) directly.\n",
    "\n",
    "4. base is a string that represents the main website.\n",
    "5. In this case, it’s the root of Wikipedia.\n",
    "6. Later, any relative link will be joined with this base.\n",
    "\n",
    "7. link is a relative URL, meaning it does not contain the full website address, only the path after the domain.\n",
    "8. Here /wiki/Taiwan.html refers to a page inside Wikipedia.\n",
    "\n",
    "9. combine base and relative link.\n",
    "10. urljoin(base,link) will join the two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a2632b8-8f75-4122-ba5a-0bed020fd0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Taiwan.html\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urljoin\n",
    "base = \"https://en.wikipedia.org\"\n",
    "link = \"/wiki/Taiwan.html\"\n",
    "address = urljoin(base, link)\n",
    "print(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc086476-9e49-497b-9f5d-f22a17aa6cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
